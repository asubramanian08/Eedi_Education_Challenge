{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup + Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-20 09:53:06.706865: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data (only do this once!)\n",
    "!wget https://dqanonymousdata.blob.core.windows.net/neurips-public/data.zip\n",
    "!unzip data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Data-frames\n",
    "BASE, EXT = 'data/metadata/', '_task_1_2.csv'\n",
    "TRAIN = pd.read_csv('data/train_data/train' + EXT)\n",
    "SUBJECT = pd.read_csv(BASE + 'subject_metadata.csv')\n",
    "QUESTION = pd.read_csv(BASE + 'question_metadata' + EXT)\n",
    "QUESTION['SubjectId'] = [list(map(int,x[1:-1].split(', '))) for x in QUESTION['SubjectId']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set DATA variable\n",
    "DATA = QUESTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic information\n",
    "print('What is the type of the data: ' + str(type(DATA)))\n",
    "print('Structure of the data: ' + str(DATA.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General information\n",
    "DATA.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First 5 entries\n",
    "DATA.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis: Understanding Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION_INFO = TRAIN.groupby('QuestionId')['IsCorrect'].agg(['mean', 'count', 'sum'])\n",
    "QUESTION_INFO = QUESTION_INFO.sort_values(by='mean')\n",
    "plt.plot(QUESTION_INFO['mean'].values)\n",
    "plt.title('Mean of correct answers per question')\n",
    "plt.xlabel('User Number')\n",
    "plt.ylabel('Average Correct Answers')\n",
    "plt.grid(color='gray', linestyle='-', linewidth=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Encode the subjects into each question\n",
    "subject_map = {x: y for x, y in zip(SUBJECT.SubjectId, SUBJECT.Name)}\n",
    "QUESTION = QUESTION.join(QUESTION.SubjectId.explode().apply(lambda x: subject_map[x]).str.get_dummies().groupby(level=0).sum().astype(bool))\n",
    "temp = QUESTION.iloc[0]['SubjectId'] + [1189, 130]\n",
    "QUESTION = QUESTION.drop(columns=['SubjectId']).set_index('QuestionId')\n",
    "for x in temp: # Last two should be False\n",
    "    print(QUESTION[subject_map[x]].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create STUDENT features (average of correct answers per subject)\n",
    "STUDENT = TRAIN.groupby('UserId')['IsCorrect'].agg(average='mean', num_questions='count')\n",
    "for _, x in subject_map.items(): # Takes about 3 minutes\n",
    "    select = set(QUESTION.loc[QUESTION[x] == True].index.values)\n",
    "    averages = TRAIN[TRAIN['QuestionId'].isin(select)].groupby('UserId')['IsCorrect'].mean()\n",
    "    STUDENT = pd.concat((STUDENT, averages), axis=1)\n",
    "    STUDENT.rename(columns={'IsCorrect': x}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388 27613 118971\n"
     ]
    }
   ],
   "source": [
    "# High use values\n",
    "FEATURE_COUNT = len(subject_map)\n",
    "QUESTION_COUNT = QUESTION.shape[0]\n",
    "STUDENT_COUNT = STUDENT.shape[0]\n",
    "print(FEATURE_COUNT, QUESTION_COUNT, STUDENT_COUNT)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning: Content-Based Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCALE THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, 388)]        0           []                               \n",
      "                                                                                                  \n",
      " input_10 (InputLayer)          [(None, 388)]        0           []                               \n",
      "                                                                                                  \n",
      " sequential_8 (Sequential)      (None, 32)           136608      ['input_9[0][0]']                \n",
      "                                                                                                  \n",
      " sequential_9 (Sequential)      (None, 32)           136608      ['input_10[0][0]']               \n",
      "                                                                                                  \n",
      " tf.math.l2_normalize_8 (TFOpLa  (None, 32)          0           ['sequential_8[0][0]']           \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.math.l2_normalize_9 (TFOpLa  (None, 32)          0           ['sequential_9[0][0]']           \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " dot_4 (Dot)                    (None, 1)            0           ['tf.math.l2_normalize_8[0][0]', \n",
      "                                                                  'tf.math.l2_normalize_9[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 273,216\n",
      "Trainable params: 273,216\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "num_outputs = 32\n",
    "user_NN = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(units=256, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=num_outputs, activation='sigmoid'),\n",
    "])\n",
    "item_NN = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(units=256, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=num_outputs, activation='sigmoid'),\n",
    "])\n",
    "# create the user input and point to the base network\n",
    "input_user = tf.keras.layers.Input(shape=(FEATURE_COUNT))\n",
    "vu = tf.linalg.l2_normalize(user_NN(input_user), axis=1)\n",
    "# create the item input and point to the base network\n",
    "input_item = tf.keras.layers.Input(shape=(FEATURE_COUNT))\n",
    "vm = tf.linalg.l2_normalize(item_NN(input_item), axis=1)\n",
    "# compute the dot product of the two vectors vu and vm\n",
    "output = tf.keras.layers.Dot(axes=1)([vu, vm])\n",
    "# specify the inputs and output of the model and compile\n",
    "model = keras.Model([input_user, input_item], output)\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01),\n",
    "              loss=keras.losses.BinaryCrossentropy())\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TRAIN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Generate Training Data - Kernal Crashes\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X_student \u001b[39m=\u001b[39m TRAIN\u001b[39m.\u001b[39mjoin(STUDENT, on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mUserId\u001b[39m\u001b[39m'\u001b[39m, how\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39minner\u001b[39m\u001b[39m'\u001b[39m, sort\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39miloc[:, \u001b[39m8\u001b[39m:]\n\u001b[1;32m      3\u001b[0m X_question \u001b[39m=\u001b[39m TRAIN\u001b[39m.\u001b[39mjoin(QUESTION, on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mQuestionId\u001b[39m\u001b[39m'\u001b[39m, how\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39minner\u001b[39m\u001b[39m'\u001b[39m, sort\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39miloc[:, \u001b[39m6\u001b[39m:]\n\u001b[1;32m      4\u001b[0m Y \u001b[39m=\u001b[39m TRAIN[\u001b[39m'\u001b[39m\u001b[39mIsCorrect\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TRAIN' is not defined"
     ]
    }
   ],
   "source": [
    "# Generate Training Data - Kernel Crashes\n",
    "X_student = TRAIN.join(STUDENT, on='UserId', how='inner', sort=True).iloc[:, 8:]\n",
    "X_question = TRAIN.join(QUESTION, on='QuestionId', how='inner', sort=True).iloc[:, 6:]\n",
    "Y = TRAIN['IsCorrect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "16530/16530 [==============================] - 144s 9ms/step - loss: nan\n",
      "Epoch 2/10\n",
      "16530/16530 [==============================] - 138s 8ms/step - loss: nan\n",
      "Epoch 3/10\n",
      "16530/16530 [==============================] - 135s 8ms/step - loss: nan\n",
      "Epoch 4/10\n",
      "16530/16530 [==============================] - 145s 9ms/step - loss: nan\n",
      "Epoch 5/10\n",
      "16530/16530 [==============================] - 263s 16ms/step - loss: nan\n",
      "Epoch 6/10\n",
      "16530/16530 [==============================] - 135s 8ms/step - loss: nan\n",
      "Epoch 7/10\n",
      "16530/16530 [==============================] - 137s 8ms/step - loss: nan\n",
      "Epoch 8/10\n",
      "16530/16530 [==============================] - 1674s 101ms/step - loss: nan\n",
      "Epoch 9/10\n",
      "16530/16530 [==============================] - 251s 15ms/step - loss: nan\n",
      "Epoch 10/10\n",
      "16530/16530 [==============================] - 163s 10ms/step - loss: nan\n",
      "Epoch 1/10\n",
      "16530/16530 [==============================] - 137s 8ms/step - loss: nan\n",
      "Epoch 2/10\n",
      "16530/16530 [==============================] - 130s 8ms/step - loss: nan\n",
      "Epoch 3/10\n",
      "16530/16530 [==============================] - 122s 7ms/step - loss: nan\n",
      "Epoch 4/10\n",
      "16530/16530 [==============================] - 120s 7ms/step - loss: nan\n",
      "Epoch 5/10\n",
      "16530/16530 [==============================] - 122s 7ms/step - loss: nan\n",
      "Epoch 6/10\n",
      "16530/16530 [==============================] - 125s 8ms/step - loss: nan\n",
      "Epoch 7/10\n",
      "16530/16530 [==============================] - 122s 7ms/step - loss: nan\n",
      "Epoch 8/10\n",
      "16530/16530 [==============================] - 163s 10ms/step - loss: nan\n",
      "Epoch 9/10\n",
      "16530/16530 [==============================] - 415s 25ms/step - loss: nan\n",
      "Epoch 10/10\n",
      "16530/16530 [==============================] - 119s 7ms/step - loss: nan\n"
     ]
    }
   ],
   "source": [
    "# Train the model (takes too much time)\n",
    "for chunk in np.array_split(TRAIN, 30):\n",
    "    X_student = chunk.join(STUDENT, on='UserId', how='inner', sort=True).iloc[:, 8:]\n",
    "    X_question = chunk.join(QUESTION, on='QuestionId', how='inner', sort=True).iloc[:, 6:]\n",
    "    Y = chunk['IsCorrect']\n",
    "    model.fit([X_student, X_question], Y, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Aug 30 2022, 05:12:36) [Clang 13.1.6 (clang-1316.0.21.2.5)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
